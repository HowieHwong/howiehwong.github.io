---
layout: homepage
---

## About Me

I'm a PhD student in [MINE Lab](https://mine-lab-nd.github.io/) of Computer Science and Engineering (CSE) at the [University of Notre Dame](https://www.nd.edu/) starting Fall 2024, supervised by [Prof. Xiangliang Zhang](https://scholar.google.com/citations?user=BhRJe4wAAAAJ&hl=en). I obtained a bachelor's degree from [Sichuan University](https://www.scu.edu.cn/) in 2024. Previously, I was a visiting student under the guidance of [Prof. Lichao Sun](https://lichao-sun.github.io/). This experience was enhanced by mentorship from [Prof. Philip S. Yu](https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en). Earlier before, I worked under [Prof. Tang Jie](https://keg.cs.tsinghua.edu.cn/jietang/) and [Dr. Xiao Liu](https://scholar.google.com.hk/citations?user=VKI8EhUAAAAJ&hl=zh-CN) at Tsinghua University.

> I am seeking potential research collaborations. If you are interested, please [contact me](&#40;mailto:yhuang37@nd.edu&#41;).

## Research Interests

My research is centered on three pivotal questions:

- **How can we deepen our understanding of the trustworthiness of foundational generative models?** This line of inquiry seeks to develop robust frameworks for evaluating trustworthiness and to identify strategies for enhancing the trustworthiness of these models within specific application domains. This includes: [TrustLLM (ICML'24)](https://arxiv.org/abs/2401.05561), [LLM-as-a-Coauthor (NAACL'24)](https://aclanthology.org/2024.findings-naacl.29/), [Attack LLM Judge (ACM CCS'24)](https://arxiv.org/abs/2403.17710), [FakeGPT (WWW'24)](https://dl.acm.org/doi/abs/10.1145/3589335.3651509), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), [HonestLLM (NeurIPS'24)](https://arxiv.org/abs/2406.00380), [TrustNLP@NAACL'24](https://arxiv.org/abs/2407.16686), and [ObscurePrompt](https://arxiv.org/abs/2406.13662).

- **Is there a superior approach to achieving Artificial General Intelligence (AGI)?** This research emphasizes data-centric methods to enable scalable model alignment and evolution, ensuring that they adhere to human values and ethical paradigms throughout the development process. This includes: [AlignBench (ACL'24)](https://arxiv.org/abs/2311.18743), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), and [UniGen](https://arxiv.org/abs/2406.18966).

- **To what extent can current AI technologies effectively benefit downstream applications?** This research area critically assesses the practical impact of generative models, with a particular focus on their application and AI4Science, exploring its transformative potential and interdisciplinary contributions in fields such as agentic models, social sciences, and beyond. This includes: [MetaTool (ICLR'24)](https://arxiv.org/abs/2310.03128), [PsychometricBench](https://arxiv.org/abs/2406.17675), [AwareBench](https://arxiv.org/abs/2401.17882) and [GUI-World](https://arxiv.org/abs/2406.10819).

## News

- *2024.09*  &nbsp; [HonestLLM](https://arxiv.org/abs/2406.00380) has been accepted by NeurIPS 2024! Congratulations to [Chujie](https://flossiee.github.io/)! Another paper has been accepted by main conference of EMNLP 2024!
- *2024.08* &nbsp; [Attack LLM-as-a-Judge](https://arxiv.org/abs/2403.17710) has been accepted by ACM CCS 2024!
- *2024.07* &nbsp; OpenAIâ€™s Researcher Access Program is Awarded.
- *2024.05* &nbsp; [TrustLLM](https://trustllmbenchmark.github.io/TrustLLM-Website/) has been accepted by ICML 2024! Thanks to all the collaborators. See you in Vienna! Another paper has been accepted by main conference of ACL 2024!
- *2024.03* &nbsp; One paper has been accepted by NAACL 2024! Congratulations to [Qihui](https://mask-hui.github.io/), [Chujie](https://flossiee.github.io/) and [Dongping](https://dongping-chen.github.io/)! Another paper has been accepted as a short paper of WWW 2024!
- *2024.02* &nbsp; Thanks for the invited talk on TrustLLM Project! @ [IBM Research](https://research.ibm.com/)
- *2024.01* &nbsp; [MetaTool](https://arxiv.org/abs/2310.03128) has been accepted by ICLR 2024! Finish research internship at Tsinghua University KEG & Zhipu Inc.!

## Selected Publication

**Disclaimer**: This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright.

- [TrustLLM: Trustworthiness in Large Language Models](https://proceedings.mlr.press/v235/huang24x.html)

  **Yue Huang**, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, et al.

  **ICML 2024**

- [MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use](https://arxiv.org/abs/2310.03128)
  **Yue Huang**, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, Yao Wan, Neil Zhenqiang Gong, Lichao Sun

  **ICLR 2024**

- [1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?](https://arxiv.org/abs/2406.14721) 

  **Yue Huang**, Chenrui Fan, Yuan Li, Siyuan Wu, et al.

  **EMNLP 2024**

- [HonestLLM: Toward an Honest and Helpful Large Language Model](https://arxiv.org/abs/2406.00380) 

  Chujie Gao\*, Siyuan Wu\*,     **Yue Huang\***, Qihui Zhang\*, Dongping Chen\*, et al. (*: Equal Contribution)

  **NeurIPS 2024**

