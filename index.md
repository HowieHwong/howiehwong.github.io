---
layout: homepage
---

## About Me

I'm a first-year PhD student in [MINE Lab](https://mine-lab-nd.github.io/) of Computer Science and Engineering (CSE) at the [University of Notre Dame](https://www.nd.edu/) starting Fall 2024, supervised by [Prof. Xiangliang Zhang](https://scholar.google.com/citations?user=BhRJe4wAAAAJ&hl=en). I obtained my bachelor's degree from [Sichuan University](https://www.scu.edu.cn/) in 2024. Previously, I was a visiting student under the guidance of [Prof. Lichao Sun](https://lichao-sun.github.io/). This experience was enhanced by mentorship from [Prof. Philip S. Yu](https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en). Earlier before, I worked under [Prof. Tang Jie](https://keg.cs.tsinghua.edu.cn/jietang/) and [Dr. Xiao Liu](https://scholar.google.com.hk/citations?user=VKI8EhUAAAAJ&hl=zh-CN) at Tsinghua University.


<div style="border: 2px solid #0078D4; padding: 15px; border-radius: 10px; background-color: #F0F8FF; font-size: 16px;">
    <p>
        I welcome the opportunity to connect with colleagues in my field as well as those from interdisciplinary areas, as I believe collaboration is immensely valuable. <br>
        If you are interested in my research, please feel free to contact me 
        <a href="mailto:yhuang37@nd.edu" style="color: #0078D4; font-weight: bold;">via email</a>.
    </p>
</div>


## Research Interests

My research is centered on three pivotal questions:

- **How can we deepen our understanding of the trustworthiness of foundational generative models?** This line of inquiry seeks to develop robust frameworks for evaluating trustworthiness and to identify strategies for enhancing the trustworthiness of these models within specific application domains. This includes: [TrustLLM (ICML'24)](https://arxiv.org/abs/2401.05561), [LLM-as-a-Coauthor (NAACL'24)](https://aclanthology.org/2024.findings-naacl.29/), [Attack LLM Judge (ACM CCS'24)](https://arxiv.org/abs/2403.17710), [FakeGPT (WWW'24)](https://dl.acm.org/doi/abs/10.1145/3589335.3651509), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), [HonestLLM (NeurIPS'24)](https://arxiv.org/abs/2406.00380), [TrustNLP@NAACL'24](https://arxiv.org/abs/2407.16686), and [ObscurePrompt](https://arxiv.org/abs/2406.13662), [Bias of LLM Judge (ICLR'25)](https://openreview.net/forum?id=3GTtZFiajM).

- **Is there a superior approach to achieving Artificial General Intelligence (AGI)?** This research emphasizes data-centric methods to enable scalable model alignment and evolution, ensuring that they adhere to human values and ethical paradigms throughout the development process. This includes: [AlignBench (ACL'24)](https://arxiv.org/abs/2311.18743), [Multilingual Alignment (EMNLP'24)](https://arxiv.org/abs/2406.14721), and [DataGen (ICLR'25)](https://openreview.net/forum?id=F5R0lG74Tu), [Interleave Generation (ICLR'25)](https://openreview.net/forum?id=rDLgnYLM5b).

- **To what extent can current AI technologies effectively benefit downstream applications?** This research area critically assesses the practical impact of generative models, with a particular focus on their application and AI4Science, exploring its transformative potential and interdisciplinary contributions in fields such as agentic models, social sciences, and beyond. This includes: [MetaTool (ICLR'24)](https://arxiv.org/abs/2310.03128), [PsychometricBench](https://arxiv.org/abs/2406.17675), and [GUI-World (ICLR'25)](https://arxiv.org/abs/2406.10819).

## News

<span style="color:rgb(2, 44, 122);">I will give four invited talks/guest lectures about the ''Socially Responsible and Trustworthy Generative Model'' @USC (2.24) @UVA (3.24) @KAUST (4.7~4.10) @UIUC (5.9)</span>

Check out latest preprints: [Trustworthiness of Generative Foundation Models](https://howiehwong.github.io/TrustGen.pdf), [Contextual Distraction Vulnerability of LLM](https://howiehwong.github.io/CDV_Preprint_version.pdf), [HHH Principles](https://howiehwong.github.io/HHH_Principle_position.pdf), [Preference Leakage of LLM Judge](https://howiehwong.github.io/preference_leakage.pdf)


- *2025.01* &nbsp; Four papers have been accepted by ICLR 2025! I was selected as [KAUST Rising Stars in AI Symposium 2025](https://www.kaust.edu.sa/en/news/rising-stars-in-ai-symposium-2025) (24/300+), hosted by the [KAUST Center of Excellence for Generative AI](https://www.kaust.edu.sa/en/research/generative-ai) in Saudi Arabia from April 7-10, 2025.

- *2024.12* &nbsp; I will join IBM Research as a Research Scientist Intern in 2025 Summer. See you in Cambridge, MA.

- *2024.09*  &nbsp; [HonestLLM](https://arxiv.org/abs/2406.00380) has been accepted by NeurIPS 2024! Congratulations to [Chujie](https://flossiee.github.io/)! Another paper has been accepted by main conference of EMNLP 2024!

- *2024.08* &nbsp; [Attack LLM-as-a-Judge](https://arxiv.org/abs/2403.17710) has been accepted by ACM CCS 2024!

- *2024.07* &nbsp; OpenAIâ€™s Researcher Access Program is Awarded.

- *2024.05* &nbsp; [TrustLLM](https://trustllmbenchmark.github.io/TrustLLM-Website/) has been accepted by ICML 2024! Thanks to all the collaborators. See you in Vienna! Another paper has been accepted by main conference of ACL 2024!

- *2024.03* &nbsp; One paper has been accepted by NAACL 2024! Congratulations to [Qihui](https://mask-hui.github.io/), [Chujie](https://flossiee.github.io/) and [Dongping](https://dongping-chen.github.io/)! Another paper has been accepted as a short paper of WWW 2024!

- *2024.02* &nbsp; Thanks for the invited talk on TrustLLM Project! @ [IBM Research](https://research.ibm.com/)

- *2024.01* &nbsp; [MetaTool](https://arxiv.org/abs/2310.03128) has been accepted by ICLR 2024! Finish research internship at Tsinghua University KEG!

## Selected Publications

**Disclaimer**: This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright.

*: Equal Contribution

- [DataGen: Unified Synthetic Dataset Generation via Large Language Models](https://openreview.net/forum?id=F5R0lG74Tu&noteId=jkupmMSLvV)\\
  **Yue Huang\***, Siyuan Wu\*, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Chaowei Xiao, Jianfeng Gao, et al.\\
  <span style="color: #ae9142;">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>\\
  [\[Toolkit\]](https://github.com/HowieHwong/UniGen) [\[Website\]](https://unigen-framework.github.io/) [\[Tutotial Video\]](https://github-production-user-asset-6210df.s3.amazonaws.com/59754221/343313227-20bb9a6e-e580-4b32-97f7-46f35d3c8c6e.mp4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20250122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250122T195432Z&X-Amz-Expires=300&X-Amz-Signature=a4c3517e39d95e730aefe023f9e87bbb0803638d0a47026a576ab4173ad7115c&X-Amz-SignedHeaders=host)

- [Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge](https://openreview.net/forum?id=3GTtZFiajM)\\
  Jiayi Ye\*, Yanbo Wang\*, **Yue Huang\***, Dongping Chen, Qihui Zhang, Nuno Moniz, Tian Gao, Werner Geyer, Chao Huang, Pin-Yu Chen, Nitesh V Chawla, Xiangliang Zhang\\
  <span style="color: #ae9142;">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>\\
  [\[Website\]](https://llm-judge-bias.github.io/)

- [GUI-World: A GUI-oriented Dataset for Multimodal LLM-based Agents](https://openreview.net/forum?id=QarKTT5brZ)\\
  Dongping Chen\*, **Yue Huang\***, Siyuan Wu, Jingyu Tang, Huichi Zhou, Qihui Zhang, Zhigang He, et al.\\
  <span style="color: #ae9142;">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>\\
  [\[Website\]](https://gui-world.github.io/) [\[Dataset\]](https://huggingface.co/datasets/shuaishuaicdp/GUI-World) [\[Model\]](https://huggingface.co/shuaishuaicdp/GUI-Vid)

- [Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment](https://openreview.net/forum?id=rDLgnYLM5b)\\
  Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, **Yue Huang**, Yao Wan, Pan Zhou, Ranjay Krishna\\
  <span style="color: #ae9142;">The Thirteenth International Conference on Learning Representations (ICLR 2025 Spotlight)</span>\\
  [\[Website\]](https://interleave-eval.github.io/) [\[Code\]](https://github.com/Dongping-Chen/ISG)

- [TrustLLM: Trustworthiness in Large Language Models](https://proceedings.mlr.press/v235/huang24x.html)\\
  **Yue Huang**, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, et al.\\
  <span style="color: #ae9142;">2024 International Conference on Machine Learning (ICML 2024)</span>\\
  (Highlighted by United States Department of Homeland Security (DHS) & International AI Safety Report, Invited Talk at IBM Research)\\
  [\[Code&Toolkit\]](https://howiehwong.github.io/TrustLLM/) [\[Website\]](https://trustllmbenchmark.github.io/TrustLLM-Website/) [\[Dataset\]](https://atlas.nomic.ai/map/f64e87d3-c769-4a90-b15d-9dc833acc8ba/8e9d7045-503b-4ba0-bc64-7201cb7aacee?xs=-16.14086&xf=-1.88776&ys=-7.54937&yf=3.88213) [\[Docs.\]](https://howiehwong.github.io/TrustLLM/)

- [MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use](https://arxiv.org/abs/2310.03128)\\
  **Yue Huang**, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, et al.\\
  <span style="color: #ae9142;"> The Twelfth International Conference on Learning Representations (ICLR 2024)</span>\\
  [\[Code\]](https://github.com/HowieHwong/MetaTool)

- [1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?](https://arxiv.org/abs/2406.14721)\\
  **Yue Huang**\*, Chenrui Fan\*, Yuan Li, Siyuan Wu, et al.\\
  <span style="color: #ae9142;">The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)</span>

- [HonestLLM: Toward an Honest and Helpful Large Language Model](https://arxiv.org/abs/2406.00380) \\
  Chujie Gao\*, Siyuan Wu\*, **Yue Huang\***, Dongping Chen\*, Qihui Zhang\*, et al. \\
  <span style="color: #ae9142;">Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)</span>\\
  [\[Code\]](https://github.com/Flossiee/HonestyLLM)

- [Optimization-based Prompt Injection Attack to LLM-as-a-Judge](https://arxiv.org/abs/2403.17710)\\
  Jiawen Shi, Zenghui Yuan, Yinuo Liu, **Yue Huang**, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong\\
  <span style="color: #ae9142;">The ACM Conference on Computer and Communications Security (ACM CCS 2024)</span>\\
  [\[Code\]](https://github.com/ShiJiawenwen/JudgeDeceiver)

- [LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?](https://arxiv.org/abs/2401.05952)\\
  Qihui Zhang\*, Chujie Gao\*, Dongping Chen\*, **Yue Huang**, et al.  
  <span style="color: #ae9142;">2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Findings of NAACL 2024)</span>\\
  [\[Code\]](https://github.com/Dongping-Chen/MixSet) [\[Website\]](https://llm-coauthor.github.io/)

- [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://arxiv.org/abs/2311.18743)\\
  Xiao Liu\*, Xuanyu Lei\*, Shengyuan Wang, **Yue Huang**, Zhuoer Feng, et al.\\
  <span style="color: #ae9142;">The 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)</span>\\
  [\[Code\]](https://github.com/THUDM/AlignBench) [\[Website\]](https://llmbench.ai/align)

- [From Creation to Clarification: ChatGPT's Journey Through the Fake News Quagmire]()\\
  **Yue Huang**, Kai Shu, Philip S. Yu, Lichao Sun\\
  <span style="color: #ae9142;">2024 ACM Web Conference (WWW 2024)</span>

## Talks
- *2025.02* Toward Socially Impactful and Trustworthy Generative Foundation Models @ [USC](https://www.usc.edu/) [\[Slides\]](https://howiehwong.github.io/Socially_Trustworthy_GenFMs.pdf)

- *2024.07* Bias of Large Language Models @ [TUM](https://www.tum.de/en/)

- *2024.02* Trustworthiness in Large Language Models @ [IBM Research](https://research.ibm.com/)





## Honors and Awards
- *2025.01* KAUST AI Rising Star

- *2024.07* OpenAIâ€™s Researcher Access Program and API

- *2024.01* Microsoft Accelerate Foundation Models Research is awarded (Project: [TrustLLM](https://github.com/HowieHwong/TrustLLM) & Lead PI: [Lichao Sun](https://lichao-sun.github.io/))

## Academic Participation

- Journal Reviewer: IEEE Transactions on Artificial Intelligence (TAI), IEEE Transactions on Dependable and Secure Computing (TDSC), IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP),  ACM Transactions on Intelligent Systems and Technology (ACM TIST)

- Conference Reviewer: ICLR, ICML, ICDM, WWW, ACL Rolling Review, EMNLP Demo Track (2024), NAACL Demo Track (2025)

- Technical Committee Member of 2024 IEEE Computer Society North America Student Challenge

## Educations

- *2024.09 - Present*, Ph.D, <img src='assets/img/Notre_Dame.png' style='width: 1.2em;'> [University of Notre Dame](https://www.nd.edu/) 
- *2020.09 - 2024.06*, BEng., <img src='assets/img/scu.png' style='width: 1.2em;'> [Sichuan University](https://en.scu.edu.cn/) 


## Internships

- *2023.09 - 2024.01*, Research Intern at <img src='assets/img/thu.png' style='width: 1.2em;'> [Tsinghua University KEG](https://keg.cs.tsinghua.edu.cn/)
